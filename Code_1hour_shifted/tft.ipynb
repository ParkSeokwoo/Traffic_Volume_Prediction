{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10207154,"sourceType":"datasetVersion","datasetId":6308079},{"sourceId":10215854,"sourceType":"datasetVersion","datasetId":6314541}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv(\"/kaggle/input/2036traffic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/2036traffic/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:44:51.139257Z","iopub.execute_input":"2024-12-16T11:44:51.139780Z","iopub.status.idle":"2024-12-16T11:44:51.352007Z","shell.execute_reply.started":"2024-12-16T11:44:51.139723Z","shell.execute_reply":"2024-12-16T11:44:51.350797Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# X_train과 y_train 설정\nX_train = train.drop(columns=['1005004000_velocity'])\ny_train = train[['1005004000_velocity']]\n\n# X_test와 y_test 설정\nX_test = test.drop(columns=['1005004000_velocity'])\ny_test = test[['1005004000_velocity']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:44:51.353979Z","iopub.execute_input":"2024-12-16T11:44:51.354376Z","iopub.status.idle":"2024-12-16T11:44:51.364854Z","shell.execute_reply.started":"2024-12-16T11:44:51.354341Z","shell.execute_reply":"2024-12-16T11:44:51.363768Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# 타겟 컬럼과 시간 시차 설정\nTARGET = '1005004000_velocity'\nHORIZON = 1  # 1시간 시차\n\n# 1시간 시차 적용하여 데이터 생성\ntrain['y_shifted'] = train[TARGET].shift(-HORIZON)  # 1시간 이후 값을 타겟으로 설정\ntest['y_shifted'] = test[TARGET].shift(-HORIZON)\n\n# 비어 있는 데이터 제거\ntrain = train.dropna(subset=['y_shifted'])\ntest = test.dropna(subset=['y_shifted'])\n\n# X_train, y_train 설정\nX_train = train.drop(columns=[TARGET, 'y_shifted'])\ny_train = train[['y_shifted']]\n\n# X_test, y_test 설정\nX_test = test.drop(columns=[TARGET, 'y_shifted'])\ny_test = test[['y_shifted']]\n\n# 결과 출력 (확인용)\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:44:51.366328Z","iopub.execute_input":"2024-12-16T11:44:51.366822Z","iopub.status.idle":"2024-12-16T11:44:51.391531Z","shell.execute_reply.started":"2024-12-16T11:44:51.366772Z","shell.execute_reply":"2024-12-16T11:44:51.390342Z"}},"outputs":[{"name":"stdout","text":"X_train shape: (19284, 68)\ny_train shape: (19284, 1)\nX_test shape: (719, 68)\ny_test shape: (719, 1)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# 넷 다 dataframe\nprint(X_train.shape, y_train.shape, X_test.shape, y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:44:51.392727Z","iopub.execute_input":"2024-12-16T11:44:51.393030Z","iopub.status.idle":"2024-12-16T11:44:51.398567Z","shell.execute_reply.started":"2024-12-16T11:44:51.393001Z","shell.execute_reply":"2024-12-16T11:44:51.397208Z"}},"outputs":[{"name":"stdout","text":"(19284, 68) (19284, 1) (719, 68) (719, 1)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# 처리 방식 정의\nfill_methods = {\n    '강수량(mm)': 0,\n    '풍속(m/s)': 'average',\n    '적설(cm)': 0\n}\n\n# 확장 가능한 결측값 처리 함수\ndef fill_missing_expanding(df, column, max_offset=2400):\n    \"\"\"\n    결측값을 24, 48, 72, ..., max_offset 시간 뒤/전의 값으로 채우는 함수\n    \"\"\"\n    step = 24  # 24시간 간격\n    for offset in range(step, max_offset + step, step):  # 24, 48, 72, ..., max_offset\n        # 24시간 뒤와 전 값으로 채우기\n        df[column] = df[column].fillna(df[column].shift(offset))\n        df[column] = df[column].fillna(df[column].shift(-offset))\n        # 결측값이 모두 채워졌으면 반복 종료\n        if df[column].isna().sum() == 0:\n            break\n    # 남은 결측값이 있으면 ffill로 채우기\n    if df[column].isna().sum() != 0:\n        df[column] = df[column].ffill()\n    return df\n\n# 결측값 처리\nfor df in [X_train, X_test]:\n    for column in df.columns:  # 모든 컬럼에 대해 처리\n        method = fill_methods.get(column, '24-48hour')  # 명시되지 않은 경우 기본값 '24-48hour'\n        \n        if method == '24-48hour':  # 24시간 뒤/전 방식으로 채우기\n            df = fill_missing_expanding(df, column)\n        elif method == 'average':  # 평균으로 채우기\n            df[column] = df[column].fillna(df[column].mean())\n        elif method == 'ffill':  # 이전 값으로 채우기\n            df[column] = df[column].ffill()\n        else:  # 특정 값으로 채우기\n            df[column] = df[column].fillna(method)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:44:51.401243Z","iopub.execute_input":"2024-12-16T11:44:51.401848Z","iopub.status.idle":"2024-12-16T11:44:57.043825Z","shell.execute_reply.started":"2024-12-16T11:44:51.401811Z","shell.execute_reply":"2024-12-16T11:44:57.042722Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# 모든 열을 float32로 변환\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:44:57.045088Z","iopub.execute_input":"2024-12-16T11:44:57.045422Z","iopub.status.idle":"2024-12-16T11:44:57.061209Z","shell.execute_reply.started":"2024-12-16T11:44:57.045391Z","shell.execute_reply":"2024-12-16T11:44:57.060126Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"X_train.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:44:57.062402Z","iopub.execute_input":"2024-12-16T11:44:57.062740Z","iopub.status.idle":"2024-12-16T11:44:57.077393Z","shell.execute_reply.started":"2024-12-16T11:44:57.062707Z","shell.execute_reply":"2024-12-16T11:44:57.076228Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"1050003300_velocity    0\n1050020400_velocity    0\n1070000200_velocity    0\n1070000500_velocity    0\n1070001600_velocity    0\n                      ..\nis_evening_rush        0\nmonth_sin              0\nmonth_cos              0\nhour_sin               0\nhour_cos               0\nLength: 68, dtype: int64"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# X_train과 X_test를 하나로 합침\nX_combined = pd.concat([X_train, X_test], axis=0)\n\n# MinMaxScaler 적용\nscaler = MinMaxScaler()\nX_combined_scaled = pd.DataFrame(scaler.fit_transform(X_combined), columns=X_combined.columns)\n\n# 다시 분리\nX_train = X_combined_scaled.iloc[:len(X_train), :].reset_index(drop=True)\nX_test = X_combined_scaled.iloc[len(X_train):, :].reset_index(drop=True)\n\nX_train.drop([\"F-03 유입_traffic_x\", \"F-04 유출_traffic_x\"], axis=1, inplace=True)\n# 컬럼 이름 변경\nX_train.rename(columns={\"F-03 유입_traffic_y\": \"F-03 유입_traffic\"}, inplace=True)\nX_train.rename(columns={\"F-04 유출_traffic_y\": \"F-04 유출_traffic\"}, inplace=True)\n\nX_test.drop([\"F-03 유입_traffic_x\", \"F-04 유출_traffic_x\"], axis=1, inplace=True)\n# 컬럼 이름 변경\nX_test.rename(columns={\"F-03 유입_traffic_y\": \"F-03 유입_traffic\"}, inplace=True)\nX_test.rename(columns={\"F-04 유출_traffic_y\": \"F-04 유출_traffic\"}, inplace=True)\n\nX_train.columns.to_list()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:44:57.078868Z","iopub.execute_input":"2024-12-16T11:44:57.079324Z","iopub.status.idle":"2024-12-16T11:44:57.122147Z","shell.execute_reply.started":"2024-12-16T11:44:57.079286Z","shell.execute_reply":"2024-12-16T11:44:57.121016Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"['1050003300_velocity',\n '1050020400_velocity',\n '1070000200_velocity',\n '1070000500_velocity',\n '1070001600_velocity',\n '기온(°C)',\n '강수량(mm)',\n '풍속(m/s)',\n '습도(%)',\n '적설(cm)',\n 'A-12 유입_traffic',\n 'A-19 유입_traffic',\n 'A-20 유입_traffic',\n 'A-22 유입_traffic',\n 'A-22 유출_traffic',\n 'B-01 유입_traffic',\n 'B-06 유입_traffic',\n 'B-14 유입_traffic',\n 'B-14 유출_traffic',\n 'B-22 유입_traffic',\n 'B-22 유출_traffic',\n 'B-36 유출_traffic',\n 'C-02 유입_traffic',\n 'C-06 유입_traffic',\n 'C-07 유입_traffic',\n 'C-09 유출_traffic',\n 'C-17 유입_traffic',\n 'C-17 유출_traffic',\n 'C-20 유입_traffic',\n 'C-21 유출_traffic',\n 'D-04 유입_traffic',\n 'D-12 유출_traffic',\n 'D-16 유출_traffic',\n 'D-17 유입_traffic',\n 'D-17 유출_traffic',\n 'D-21 유출_traffic',\n 'D-28 유입_traffic',\n 'D-28 유출_traffic',\n 'D-31 유입_traffic',\n 'D-35 유입_traffic',\n 'D-35 유출_traffic',\n 'D-44 유출_traffic',\n 'F-02 유출_traffic',\n 'F-03 유입_traffic',\n 'F-03 유출_traffic',\n 'F-04 유출_traffic',\n 'F-05 유입_traffic',\n 'F-05 유출_traffic',\n 'F-06 유입_traffic',\n 'F-07 유입_traffic',\n 'F-07 유출_traffic',\n 'F-08 유입_traffic',\n 'F-08 유출_traffic',\n 'F-09 유입_traffic',\n 'F-09 유출_traffic',\n 'F-10 유입_traffic',\n 'F-10 유출_traffic',\n 'Year',\n 'is_weekend',\n 'is_holiday',\n 'is_morning_rush',\n 'is_evening_rush',\n 'month_sin',\n 'month_cos',\n 'hour_sin',\n 'hour_cos']"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# !pip install pytorch_forecasting\n# !pip install pytorch_lightning","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:44:57.123494Z","iopub.execute_input":"2024-12-16T11:44:57.123853Z","iopub.status.idle":"2024-12-16T11:44:57.128401Z","shell.execute_reply.started":"2024-12-16T11:44:57.123819Z","shell.execute_reply":"2024-12-16T11:44:57.127218Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import mean_absolute_percentage_error\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n# Define the temporal and static features\n\nTrain = pd.concat([X_train, y_train], axis=1)\nTarget = \"y_shifted\"\nTrain['time_idx'] = range(len(Train))\nTrain['group_id'] = 0  # Single group for all Train\nTrain\n\nTest = pd.concat([X_test, y_test], axis=1)\nTarget = \"y_shifted\"\nTest['time_idx'] = range(len(Test))\nTest['group_id'] = 0  # Single group for all Train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:44:57.129514Z","iopub.execute_input":"2024-12-16T11:44:57.129854Z","iopub.status.idle":"2024-12-16T11:44:57.145675Z","shell.execute_reply.started":"2024-12-16T11:44:57.129821Z","shell.execute_reply":"2024-12-16T11:44:57.144412Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"Train.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:44:57.147231Z","iopub.execute_input":"2024-12-16T11:44:57.147689Z","iopub.status.idle":"2024-12-16T11:44:57.158763Z","shell.execute_reply.started":"2024-12-16T11:44:57.147619Z","shell.execute_reply":"2024-12-16T11:44:57.157507Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"1050003300_velocity    0\n1050020400_velocity    0\n1070000200_velocity    0\n1070000500_velocity    0\n1070001600_velocity    0\n                      ..\nhour_sin               0\nhour_cos               0\ny_shifted              0\ntime_idx               0\ngroup_id               0\nLength: 69, dtype: int64"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"print(Train.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:44:57.160146Z","iopub.execute_input":"2024-12-16T11:44:57.160515Z","iopub.status.idle":"2024-12-16T11:44:57.169179Z","shell.execute_reply.started":"2024-12-16T11:44:57.160469Z","shell.execute_reply":"2024-12-16T11:44:57.168089Z"}},"outputs":[{"name":"stdout","text":"['1050003300_velocity', '1050020400_velocity', '1070000200_velocity', '1070000500_velocity', '1070001600_velocity', '기온(°C)', '강수량(mm)', '풍속(m/s)', '습도(%)', '적설(cm)', 'A-12 유입_traffic', 'A-19 유입_traffic', 'A-20 유입_traffic', 'A-22 유입_traffic', 'A-22 유출_traffic', 'B-01 유입_traffic', 'B-06 유입_traffic', 'B-14 유입_traffic', 'B-14 유출_traffic', 'B-22 유입_traffic', 'B-22 유출_traffic', 'B-36 유출_traffic', 'C-02 유입_traffic', 'C-06 유입_traffic', 'C-07 유입_traffic', 'C-09 유출_traffic', 'C-17 유입_traffic', 'C-17 유출_traffic', 'C-20 유입_traffic', 'C-21 유출_traffic', 'D-04 유입_traffic', 'D-12 유출_traffic', 'D-16 유출_traffic', 'D-17 유입_traffic', 'D-17 유출_traffic', 'D-21 유출_traffic', 'D-28 유입_traffic', 'D-28 유출_traffic', 'D-31 유입_traffic', 'D-35 유입_traffic', 'D-35 유출_traffic', 'D-44 유출_traffic', 'F-02 유출_traffic', 'F-03 유입_traffic', 'F-03 유출_traffic', 'F-04 유출_traffic', 'F-05 유입_traffic', 'F-05 유출_traffic', 'F-06 유입_traffic', 'F-07 유입_traffic', 'F-07 유출_traffic', 'F-08 유입_traffic', 'F-08 유출_traffic', 'F-09 유입_traffic', 'F-09 유출_traffic', 'F-10 유입_traffic', 'F-10 유출_traffic', 'Year', 'is_weekend', 'is_holiday', 'is_morning_rush', 'is_evening_rush', 'month_sin', 'month_cos', 'hour_sin', 'hour_cos', 'y_shifted', 'time_idx', 'group_id']\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Parameters\nN_TEST = 12\nN_SPLIT = 27\nmax_encoder_length = 24\nmax_prediction_length = 1\nBATCH_SIZE = 64\nLEARNING_RATE = 0.001\nTrain.astype('float32')\n# Define features\nTEMPORAL_FEATURES = ['1050003300_velocity', '1050020400_velocity', '1070000200_velocity',\n                     '1070000500_velocity', '1070001600_velocity', \n                     'A-12 유입_traffic', 'A-19 유입_traffic', 'A-20 유입_traffic', 'A-22 유입_traffic', 'A-22 유출_traffic', 'B-01 유입_traffic', 'B-06 유입_traffic', 'B-14 유입_traffic', 'B-14 유출_traffic', 'B-22 유입_traffic', 'B-22 유출_traffic', 'B-36 유출_traffic', 'C-02 유입_traffic', 'C-06 유입_traffic', 'C-07 유입_traffic', 'C-09 유출_traffic', 'C-17 유입_traffic', 'C-17 유출_traffic', 'C-20 유입_traffic', 'C-21 유출_traffic', 'D-04 유입_traffic', 'D-12 유출_traffic', 'D-16 유출_traffic', 'D-17 유입_traffic', 'D-17 유출_traffic', 'D-21 유출_traffic', 'D-28 유입_traffic', 'D-28 유출_traffic', 'D-31 유입_traffic', 'D-35 유입_traffic', 'D-35 유출_traffic', 'D-44 유출_traffic', 'F-02 유출_traffic', 'F-03 유입_traffic', 'F-03 유출_traffic', 'F-04 유출_traffic', 'F-05 유입_traffic', 'F-05 유출_traffic', 'F-06 유입_traffic', 'F-07 유입_traffic', 'F-07 유출_traffic', 'F-08 유입_traffic', 'F-08 유출_traffic', 'F-09 유입_traffic', 'F-09 유출_traffic', 'F-10 유입_traffic', 'F-10 유출_traffic',\n                     '기온(°C)', '강수량(mm)', '풍속(m/s)', '습도(%)', '적설(cm)']\nSTATIC_FEATURES = ['Year', 'is_weekend', 'is_holiday', 'is_morning_rush', 'is_evening_rush']\n\n# Fix the group_id and Year issues\ndef preprocess_data(data):\n    data['group_id'] = 0\n    return data\n\n# Split and seed settings\nts_split = TimeSeriesSplit(n_splits=N_SPLIT)\nmape_scores = []\n\n# Set random seed for reproducibility\ndef set_seed(seed):\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Temporal Fusion Transformer setup\ndef setup_tft(Train, train_idx, val_idx):\n    Train = preprocess_data(Train)  # Preprocess the dataset\n    train_data = Train.iloc[train_idx]\n    val_data = Train.iloc[val_idx]\n    assert not train_data.isnull().any().any(), \"Missing values in train_data\"\n    assert not val_data.isnull().any().any(), \"Missing values in val_data\"\n\n    print(train_data.isnull().sum().sum())\n    train_dataset = TimeSeriesDataSet(\n        train_data,\n        time_idx=\"time_idx\",\n        target=\"y_shifted\",\n        group_ids=[\"group_id\"],\n        min_encoder_length=max_encoder_length // 2,\n        max_encoder_length=max_encoder_length,\n        min_prediction_length=1,\n        max_prediction_length=max_prediction_length,\n        static_reals=STATIC_FEATURES,\n        time_varying_known_reals=TEMPORAL_FEATURES+[\"time_idx\"],\n        time_varying_unknown_reals=[\"y_shifted\"],\n        target_normalizer=None,\n        add_relative_time_idx=True,\n        add_target_scales=True,\n        add_encoder_length=True,\n    )\n\n    val_dataset = TimeSeriesDataSet.from_dataset(\n        train_dataset, val_data\n    )\n    \n    # sample = train_dataset[0]\n    # print(sample)\n    #for key, value in sample.items():\n    #    print(f\"{key}: {value.shape if hasattr(value, 'shape') else value}\")\n\n    train_dataloader = train_dataset.to_dataloader(train=True, batch_size=128, num_workers=0)\n    val_dataloader = val_dataset.to_dataloader(train=False, batch_size=128 * 10, num_workers=0)\n    \n    from pytorch_forecasting.metrics import MAE\n    \n    model = TemporalFusionTransformer.from_dataset(\n        train_dataset,\n        learning_rate=LEARNING_RATE,\n        hidden_size=16,\n        attention_head_size=4,\n        dropout=0.1,\n        hidden_continuous_size=8,\n        output_size=1,\n        loss=MAE(),\n    )\n\n    return model, train_dataloader, val_dataloader\n\n# # Loop through splits\n# for fold, (train_idx, val_idx) in enumerate(ts_split.split(Train)):\n#     if fold < N_SPLIT - N_TEST:\n#         continue\n    \n#     print(f\"TFT Fold {fold + 1} start!\")\n#     import lightning.pytorch as lp\n#     # Train TFT\n#     tft_model, train_loader, val_loader = setup_tft(Train, train_idx, val_idx)\n    \n#     trainer = lp.Trainer(max_epochs=30, accelerator=\"cpu\")\n#     trainer.fit(tft_model, train_loader, val_loader)\n\n#     # Evaluate TFT\n#     tft_model.eval()\n\n#     actuals = torch.cat([y for x, y in iter(val_loader)]).cpu().numpy()\n#     predictions = torch.cat([tft_model.predict(x) for x, y in iter(val_loader)]).cpu().numpy()\n#     mape = mean_absolute_percentage_error(actuals, predictions)\n#     mape_scores.append(mape)\n#     print(f\"TFT Fold {fold + 1}, Validation MAPE: {mape:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:44:57.171066Z","iopub.execute_input":"2024-12-16T11:44:57.171454Z","iopub.status.idle":"2024-12-16T11:44:57.189807Z","shell.execute_reply.started":"2024-12-16T11:44:57.171419Z","shell.execute_reply":"2024-12-16T11:44:57.188638Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"train_dataset = TimeSeriesDataSet(\n    Train,\n    time_idx=\"time_idx\",\n    target=\"y_shifted\",\n    group_ids=[\"group_id\"],\n    min_encoder_length=max_encoder_length // 2,\n    max_encoder_length=max_encoder_length,\n    min_prediction_length=1,\n    max_prediction_length=max_prediction_length,\n    static_reals=STATIC_FEATURES,\n    time_varying_known_reals=TEMPORAL_FEATURES + [\"time_idx\"],\n    time_varying_unknown_reals=[\"y_shifted\"],\n    target_normalizer=None,\n    add_relative_time_idx=True,\n    add_target_scales=True,\n    add_encoder_length=True,\n)\n\ntest_dataset = TimeSeriesDataSet.from_dataset(train_dataset, Test)\n\n# Dataloader setup\ntrain_dataloader = train_dataset.to_dataloader(train=True, batch_size=BATCH_SIZE, num_workers=0)\ntest_dataloader = test_dataset.to_dataloader(train=False, batch_size=BATCH_SIZE * 10, num_workers=0)\n\n# Model setup\nfrom pytorch_forecasting.metrics import MAE\nfrom pytorch_forecasting.models import TemporalFusionTransformer\n\ntft_model = TemporalFusionTransformer.from_dataset(\n    train_dataset,\n    learning_rate=LEARNING_RATE,\n    hidden_size=16,\n    attention_head_size=4,\n    dropout=0.1,\n    hidden_continuous_size=8,\n    output_size=1,\n    loss=MAE(),\n)\n\n# Trainer setup\nimport lightning.pytorch as lp\n\ntrainer = lp.Trainer(max_epochs=30, accelerator=\"cpu\")\ntrainer.fit(tft_model, train_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:44:57.192711Z","iopub.execute_input":"2024-12-16T11:44:57.193073Z","iopub.status.idle":"2024-12-16T12:51:22.648643Z","shell.execute_reply.started":"2024-12-16T11:44:57.193027Z","shell.execute_reply":"2024-12-16T12:51:22.647165Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n/opt/conda/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n/opt/conda/lib/python3.10/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py:171: UserWarning: In pytorch-forecasting models, on versions 1.1.X, the default optimizer defaults to 'adam', if pytorch_optimizer is not installed, otherwise it defaults to 'ranger' from pytorch_optimizer. From version 1.2.0, the default optimizer will be 'adam' regardless of whether pytorch_optimizer is installed, in order to minimize the number of dependencies in default parameter settings. Users who wish to ensure their code continues using 'ranger' as optimizer should ensure that pytorch_optimizer is installed, and set the optimizer parameter explicitly to 'ranger'.\n  super().__init__(loss=loss, logging_metrics=logging_metrics, **kwargs)\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\n/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\nINFO: \n   | Name                               | Type                            | Params | Mode \n------------------------------------------------------------------------------------------------\n0  | loss                               | MAE                             | 0      | train\n1  | logging_metrics                    | ModuleList                      | 0      | train\n2  | input_embeddings                   | MultiEmbedding                  | 0      | train\n3  | prescalers                         | ModuleDict                      | 1.1 K  | train\n4  | static_variable_selection          | VariableSelectionNetwork        | 5.0 K  | train\n5  | encoder_variable_selection         | VariableSelectionNetwork        | 42.2 K | train\n6  | decoder_variable_selection         | VariableSelectionNetwork        | 41.5 K | train\n7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K  | train\n8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K  | train\n9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K  | train\n10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K  | train\n11 | lstm_encoder                       | LSTM                            | 2.2 K  | train\n12 | lstm_decoder                       | LSTM                            | 2.2 K  | train\n13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544    | train\n14 | post_lstm_add_norm_encoder         | AddNorm                         | 32     | train\n15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K  | train\n16 | multihead_attn                     | InterpretableMultiHeadAttention | 676    | train\n17 | post_attn_gate_norm                | GateAddNorm                     | 576    | train\n18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K  | train\n19 | pre_output_gate_norm               | GateAddNorm                     | 576    | train\n20 | output_layer                       | Linear                          | 17     | train\n------------------------------------------------------------------------------------------------\n101 K     Trainable params\n0         Non-trainable params\n101 K     Total params\n0.406     Total estimated model params size (MB)\n2007      Modules in train mode\n0         Modules in eval mode\n/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e808dc424754b499143c410c04bc876"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:389: ReduceLROnPlateau conditioned on metric val_loss which is not available but strict is set to `False`. Skipping learning rate update.\nINFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Evaluate on test set\u001b[39;00m\n\u001b[1;32m     47\u001b[0m tft_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 48\u001b[0m actuals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     49\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([tft_model\u001b[38;5;241m.\u001b[39mpredict(x) \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(test_dataloader)])\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Calculate MAPE\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got tuple"],"ename":"TypeError","evalue":"expected Tensor as element 0 in argument 0, but got tuple","output_type":"error"}],"execution_count":29},{"cell_type":"code","source":"# Evaluate on test set\ntft_model.eval()\n\n# 실제값 수집\nactuals = torch.cat([y[0] for x, y in iter(test_dataloader)]).cpu().numpy()\n\n# 예측값 수집\npredictions = tft_model.predict(test_dataloader, mode=\"prediction\")\n\n# 예측값 디버깅\nprint(f\"Predictions type: {type(predictions)}\")\nprint(f\"Predictions shape: {predictions.shape if isinstance(predictions, torch.Tensor) else [p.shape for p in predictions]}\")\n\n# 2차원 텐서로 변환\nif isinstance(predictions, list):\n    predictions = torch.cat(predictions).cpu().numpy()\nelse:\n    predictions = predictions.cpu().numpy()\n# Calculate MAPE\nfrom sklearn.metrics import mean_absolute_percentage_error\ntest_mape = mean_absolute_percentage_error(actuals, predictions)\nprint(f\"Test MAPE: {test_mape:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T12:54:11.041016Z","iopub.execute_input":"2024-12-16T12:54:11.041445Z","iopub.status.idle":"2024-12-16T12:54:13.363779Z","shell.execute_reply.started":"2024-12-16T12:54:11.041408Z","shell.execute_reply":"2024-12-16T12:54:13.362692Z"}},"outputs":[{"name":"stderr","text":"INFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\n/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"name":"stdout","text":"Predictions type: <class 'torch.Tensor'>\nPredictions shape: torch.Size([719, 1])\nTest MAPE: 0.1023\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\james\\Documents\\Traffic_Volume_Prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(file_path + r\"\\Data\\train.csv\")\n",
    "test = pd.read_csv(file_path + r\"\\Data\\test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X, y 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (19261, 21)\n",
      "y_train shape: (19261, 1)\n",
      "X_test shape: (696, 21)\n",
      "y_test shape: (696, 1)\n"
     ]
    }
   ],
   "source": [
    "# 타겟 컬럼과 시간 시차 설정\n",
    "TARGET = '1005004000_velocity'\n",
    "HORIZON = 24  # 24시간 시차\n",
    "\n",
    "# 24시간 시차 적용하여 데이터 생성\n",
    "train['y_shifted'] = train[TARGET].shift(-HORIZON)  # 24시간 이후 값을 타겟으로 설정\n",
    "test['y_shifted'] = test[TARGET].shift(-HORIZON)\n",
    "\n",
    "# 비어 있는 데이터 제거\n",
    "train = train.dropna(subset=['y_shifted'])\n",
    "test = test.dropna(subset=['y_shifted'])\n",
    "\n",
    "# X_train, y_train 설정\n",
    "X_train = train.drop(columns=[TARGET, 'y_shifted'])\n",
    "y_train = train[['y_shifted']]\n",
    "\n",
    "# X_test, y_test 설정\n",
    "X_test = test.drop(columns=[TARGET, 'y_shifted'])\n",
    "y_test = test[['y_shifted']]\n",
    "\n",
    "# 결과 출력 (확인용)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window 방식의 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링(lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation MAPE: 0.08775063824570846\n",
      "validation MAPE: 0.09774180934281307\n",
      "validation MAPE: 0.14029358478708046\n",
      "validation MAPE: 0.16677774590546213\n",
      "validation MAPE: 0.0950319817855999\n",
      "validation MAPE: 0.07955843453799241\n",
      "validation MAPE: 0.0695487986484141\n",
      "validation MAPE: 0.0756655798930508\n",
      "validation MAPE: 0.07872655838885147\n",
      "validation MAPE: 0.08082837645798534\n",
      "validation MAPE: 0.1020871327172352\n",
      "validation MAPE: 0.08828805086985694\n",
      "\n",
      "Results: \n",
      "Average Validation MAPE: 0.09685822429833751\n",
      "Validation MAPE Std Dev: 0.027451703603425193\n",
      "Final Test MAPE: 0.08156596099087708\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "# 설정 값\n",
    "N_TEST = 12\n",
    "N_SPLIT = 27\n",
    "\n",
    "lgb_params = {\n",
    "    'learning_rate': 0.04920408281422388,\n",
    "    'num_leaves': 84,\n",
    "    'max_depth': 9,\n",
    "    'min_child_samples': 62,\n",
    "    'subsample': 0.8114337992568297,\n",
    "    'colsample_bytree': 0.9241942074377165,\n",
    "    'reg_alpha': 0.13177582213039427,\n",
    "    'reg_lambda': 0.8708071123519207,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# TimeSeriesSplit 설정\n",
    "tscv = TimeSeriesSplit(n_splits=N_SPLIT)\n",
    "\n",
    "# MAPE 점수 리스트\n",
    "mape_scores = []\n",
    "trials = 1\n",
    "\n",
    "# TimeSeriesSplit을 이용한 검증\n",
    "for train_idx, val_idx in tscv.split(X_train):\n",
    "    if trials <= N_SPLIT - N_TEST:\n",
    "        trials += 1\n",
    "        continue\n",
    "\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    # LightGBM 모델 학습\n",
    "    lgb_model = lgb.LGBMRegressor(objective='mape', verbose=-1, **lgb_params)\n",
    "    lgb_model.fit(X_tr, y_tr.values.ravel()) \n",
    "    \n",
    "    # 예측 및 MAPE 계산\n",
    "    y_pred = lgb_model.predict(X_val)\n",
    "    mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "    mape_scores.append(mape)\n",
    "    print(f\"validation MAPE: {mape}\")\n",
    "\n",
    "# 테스트 세트에 대한 최종 예측\n",
    "lgb_model = lgb.LGBMRegressor(objective='mape', verbose=-1, **lgb_params)\n",
    "lgb_model.fit(X_train, y_train.values.ravel()) \n",
    "y_test_pred = lgb_model.predict(X_test)\n",
    "test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\")\n",
    "print(\"Results: \")\n",
    "print(\"Average Validation MAPE:\", np.mean(mape_scores))\n",
    "print(\"Validation MAPE Std Dev:\", np.std(mape_scores))\n",
    "print(\"Final Test MAPE:\", test_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터 최적화(lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "# import optuna\n",
    "# import numpy as np\n",
    "\n",
    "# # 설정 값\n",
    "# N_TEST = 12\n",
    "# N_SPLIT = 27\n",
    "\n",
    "# # TimeSeriesSplit 설정\n",
    "# tscv = TimeSeriesSplit(n_splits=N_SPLIT)\n",
    "\n",
    "# # 최적화 목표 함수 정의\n",
    "# def objective(trial):\n",
    "#     # 하이퍼파라미터 탐색 범위 정의\n",
    "#     param = {\n",
    "#         'objective': 'mape',\n",
    "#         'metric': 'mape',\n",
    "#         'verbosity': -1,\n",
    "#         'boosting_type': 'gbdt',\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 20, 200),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "#         'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True)\n",
    "#     }\n",
    "\n",
    "    \n",
    "#     mape_scores = []\n",
    "#     trials = 1\n",
    "\n",
    "#     # TimeSeriesSplit을 사용한 교차 검증\n",
    "#     for train_idx, val_idx in tscv.split(X_train):\n",
    "#         if trials <= N_SPLIT - N_TEST:\n",
    "#             trials += 1\n",
    "#             continue\n",
    "\n",
    "#         X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "#         y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "#         # 모델 학습\n",
    "#         model = lgb.LGBMRegressor(**param)\n",
    "#         model.fit(X_tr, y_tr.values.ravel())\n",
    "\n",
    "#         # 예측 및 MAPE 계산\n",
    "#         y_pred = model.predict(X_val)\n",
    "#         mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "#         mape_scores.append(mape)\n",
    "\n",
    "#     # 평균 MAPE 반환 (Optuna가 최소화할 값)\n",
    "#     return np.mean(mape_scores)\n",
    "\n",
    "# # Optuna 스터디 생성 및 최적화 실행\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=100)\n",
    "\n",
    "# # 최적 하이퍼파라미터 및 결과 출력\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "# print(\"  Value: \", trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")\n",
    "\n",
    "# # 최적 파라미터로 최종 모델 학습 및 테스트 예측\n",
    "# best_params = trial.params\n",
    "# model = lgb.LGBMRegressor(**best_params)\n",
    "# model.fit(X_train, y_train.values.ravel())\n",
    "# y_test_pred = model.predict(X_test)\n",
    "# test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "# # 최종 결과 출력\n",
    "# print(\"\\nFinal Test MAPE:\", test_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링(xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation MAPE: 0.09069390682985724\n",
      "validation MAPE: 0.10212619530635786\n",
      "validation MAPE: 0.1411007225792947\n",
      "validation MAPE: 0.16522680515146815\n",
      "validation MAPE: 0.09768080926933179\n",
      "validation MAPE: 0.08138588994308778\n",
      "validation MAPE: 0.07050078935998193\n",
      "validation MAPE: 0.07590160974462776\n",
      "validation MAPE: 0.0820699968183909\n",
      "validation MAPE: 0.08535114959557775\n",
      "validation MAPE: 0.10749362720147156\n",
      "validation MAPE: 0.08925877499679542\n",
      "\n",
      "Results:\n",
      "Average Validation MAPE: 0.0990658563996869\n",
      "Validation MAPE Std Dev: 0.02666905177010113\n",
      "Final Test MAPE: 0.08355022500079319\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "# 설정 값\n",
    "N_TEST = 12\n",
    "N_SPLIT = 27\n",
    "\n",
    "# TimeSeriesSplit 설정\n",
    "tscv = TimeSeriesSplit(n_splits=N_SPLIT)\n",
    "\n",
    "xgb_params = {\n",
    "    'n_jobs': -1,\n",
    "    'learning_rate': 0.05794263457885568,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 4,\n",
    "    'subsample': 0.7344045283452703,\n",
    "    'colsample_bytree': 0.9038004924012054,\n",
    "    'reg_alpha': 0.021676042228145752,\n",
    "    'reg_lambda': 0.0010158057245436504,\n",
    "}\n",
    "\n",
    "# MAPE 점수 리스트\n",
    "mape_scores = []\n",
    "trials = 1\n",
    "\n",
    "# TimeSeriesSplit을 이용한 검증\n",
    "for train_idx, val_idx in tscv.split(X_train):\n",
    "    if trials <= N_SPLIT - N_TEST:\n",
    "        trials += 1\n",
    "        continue\n",
    "\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    # XGBoost 모델 학습\n",
    "    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', verbosity=0, **xgb_params)\n",
    "    xgb_model.fit(X_tr, y_tr.values.ravel())\n",
    "    \n",
    "    # 예측 및 MAPE 계산\n",
    "    y_pred = xgb_model.predict(X_val)\n",
    "    mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "    mape_scores.append(mape)\n",
    "    print(f\"validation MAPE: {mape}\")\n",
    "\n",
    "# 테스트 세트에 대한 최종 예측\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', verbosity=0, **xgb_params)\n",
    "xgb_model.fit(X_train, y_train.values.ravel())\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\nResults:\")\n",
    "print(\"Average Validation MAPE:\", np.mean(mape_scores))\n",
    "print(\"Validation MAPE Std Dev:\", np.std(mape_scores))\n",
    "print(\"Final Test MAPE:\", test_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터 최적화(xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "# import optuna\n",
    "# import numpy as np\n",
    "\n",
    "# # 설정 값\n",
    "# N_TEST = 12\n",
    "# N_SPLIT = 27\n",
    "\n",
    "# # TimeSeriesSplit 설정\n",
    "# tscv = TimeSeriesSplit(n_splits=N_SPLIT)\n",
    "\n",
    "# # 최적화 목표 함수 정의\n",
    "# def objective(trial):\n",
    "#     # 하이퍼파라미터 탐색 범위 정의\n",
    "#     param = {\n",
    "#         'objective': 'reg:squarederror',  # 기본 손실 함수 사용\n",
    "#         'verbosity': 0,\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "#         'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "#         'n_jobs': -1  \n",
    "#     }\n",
    "\n",
    "    \n",
    "#     mape_scores = []\n",
    "#     trials = 1\n",
    "\n",
    "#     # TimeSeriesSplit을 사용한 교차 검증\n",
    "#     for train_idx, val_idx in tscv.split(X_train):\n",
    "#         if trials <= N_SPLIT - N_TEST:\n",
    "#             trials += 1\n",
    "#             continue\n",
    "\n",
    "#         X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "#         y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "#         # 모델 학습\n",
    "#         model = xgb.XGBRegressor(**param)\n",
    "#         model.fit(X_tr, y_tr.values.ravel())\n",
    "\n",
    "#         # 예측 및 MAPE 계산\n",
    "#         y_pred = model.predict(X_val)\n",
    "#         mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "#         mape_scores.append(mape)\n",
    "\n",
    "#     # 평균 MAPE 반환 (Optuna가 최소화할 값)\n",
    "#     return np.mean(mape_scores)\n",
    "\n",
    "# # Optuna 스터디 생성 및 최적화 실행\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=100)\n",
    "\n",
    "# # 최적 하이퍼파라미터 및 결과 출력\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "# print(\"  Value: \", trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")\n",
    "\n",
    "# # 최적 파라미터로 최종 모델 학습 및 테스트 예측\n",
    "# best_params = trial.params\n",
    "# model = xgb.XGBRegressor(**best_params)\n",
    "# model.fit(X_train, y_train.values.ravel())\n",
    "# y_test_pred = model.predict(X_test)\n",
    "# test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "# # 최종 결과 출력\n",
    "# print(\"\\nFinal Test MAPE:\", test_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링(random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation MAPE: 0.08844286848516413\n",
      "validation MAPE: 0.10091990474735323\n",
      "validation MAPE: 0.13805966295962172\n",
      "validation MAPE: 0.16717390321218856\n",
      "validation MAPE: 0.09966874936303986\n",
      "validation MAPE: 0.0824988079769891\n",
      "validation MAPE: 0.07005998014881469\n",
      "validation MAPE: 0.07659970567573386\n",
      "validation MAPE: 0.08021508717811333\n",
      "validation MAPE: 0.08193017865940815\n",
      "validation MAPE: 0.10825987336891912\n",
      "validation MAPE: 0.0921056149654756\n",
      "\n",
      "Results:\n",
      "Average Validation MAPE: 0.09882786139506844\n",
      "Validation MAPE Std Dev: 0.02689127162947541\n",
      "Final Test MAPE: 0.08226829927816853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "# 설정 값\n",
    "N_TEST = 12\n",
    "N_SPLIT = 27\n",
    "\n",
    "# TimeSeriesSplit 설정\n",
    "tscv = TimeSeriesSplit(n_splits=N_SPLIT)\n",
    "\n",
    "rf_params ={\n",
    "    'n_estimators': 202,\n",
    "    'max_depth': 22,\n",
    "    'min_samples_split': 12,\n",
    "    'min_samples_leaf': 4,\n",
    "    'max_features': 0.5197759173571685,\n",
    "    'n_jobs': -1,  # 모든 CPU 코어 사용\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# MAPE 점수 리스트\n",
    "mape_scores = []\n",
    "trials = 1\n",
    "\n",
    "# TimeSeriesSplit을 이용한 검증\n",
    "for train_idx, val_idx in tscv.split(X_train):\n",
    "    if trials <= N_SPLIT - N_TEST:\n",
    "        trials += 1\n",
    "        continue\n",
    "\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    # RandomForest 모델 학습\n",
    "    rf_model = RandomForestRegressor( **rf_params)\n",
    "    rf_model.fit(X_tr, y_tr.values.ravel())\n",
    "    \n",
    "    # 예측 및 MAPE 계산\n",
    "    y_pred = rf_model.predict(X_val)\n",
    "    mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "    mape_scores.append(mape)\n",
    "    print(f\"validation MAPE: {mape}\")\n",
    "\n",
    "# 테스트 세트에 대한 최종 예측\n",
    "rf_model = RandomForestRegressor(**rf_params)\n",
    "rf_model.fit(X_train, y_train.values.ravel())\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\nResults:\")\n",
    "print(\"Average Validation MAPE:\", np.mean(mape_scores))\n",
    "print(\"Validation MAPE Std Dev:\", np.std(mape_scores))\n",
    "print(\"Final Test MAPE:\", test_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터 최적화(random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "# import optuna\n",
    "# import numpy as np\n",
    "\n",
    "# # 설정 값\n",
    "# N_TEST = 12\n",
    "# N_SPLIT = 27\n",
    "\n",
    "# # TimeSeriesSplit 설정\n",
    "# tscv = TimeSeriesSplit(n_splits=N_SPLIT)\n",
    "\n",
    "# # 최적화 목표 함수 정의\n",
    "# def objective(trial):\n",
    "#     # 하이퍼파라미터 탐색 범위 정의\n",
    "#     param = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "#         'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "#         'max_features': trial.suggest_float('max_features', 0.1, 1.0),  # 범위를 float로 지정\n",
    "#         'n_jobs': -1,  # 모든 CPU 코어 사용\n",
    "#         'random_state': 42\n",
    "#     }\n",
    "    \n",
    "#     mape_scores = []\n",
    "#     trials = 1\n",
    "\n",
    "#     # TimeSeriesSplit을 사용한 교차 검증\n",
    "#     for train_idx, val_idx in tscv.split(X_train):\n",
    "#         if trials <= N_SPLIT - N_TEST:\n",
    "#             trials += 1\n",
    "#             continue\n",
    "\n",
    "#         X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "#         y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "#         # 모델 학습\n",
    "#         model = RandomForestRegressor(**param)\n",
    "#         model.fit(X_tr, y_tr.values.ravel())\n",
    "\n",
    "#         # 예측 및 MAPE 계산\n",
    "#         y_pred = model.predict(X_val)\n",
    "#         mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "#         mape_scores.append(mape)\n",
    "\n",
    "#     # 평균 MAPE 반환 (Optuna가 최소화할 값)\n",
    "#     return np.mean(mape_scores)\n",
    "\n",
    "# # Optuna 스터디 생성 및 최적화 실행\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=100)\n",
    "\n",
    "# # 최적 하이퍼파라미터 및 결과 출력\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "# print(\"  Value: \", trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")\n",
    "\n",
    "# # 최적 파라미터로 최종 모델 학습 및 테스트 예측\n",
    "# best_params = trial.params\n",
    "# model = RandomForestRegressor(**best_params)\n",
    "# model.fit(X_train, y_train.values.ravel())\n",
    "# y_test_pred = model.predict(X_test)\n",
    "# test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "# # 최종 결과 출력\n",
    "# print(\"\\nFinal Test MAPE:\", test_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation MAPE: 0.08806567150251042\n",
      "validation MAPE: 0.10403933974794086\n",
      "validation MAPE: 0.13982346429658926\n",
      "validation MAPE: 0.167795610798921\n",
      "validation MAPE: 0.09962885063647227\n",
      "validation MAPE: 0.08029897693264822\n",
      "validation MAPE: 0.0710570207775987\n",
      "validation MAPE: 0.07654786639528888\n",
      "validation MAPE: 0.08121865899264462\n",
      "validation MAPE: 0.0839841977030756\n",
      "validation MAPE: 0.10546317080937274\n",
      "validation MAPE: 0.08862998692299585\n",
      "\n",
      "Results:\n",
      "Average Validation MAPE: 0.09887940129300486\n",
      "Validation MAPE Std Dev: 0.02718787033688716\n",
      "Final Test MAPE: 0.08247386095206033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "# 설정 값\n",
    "N_TEST = 12\n",
    "N_SPLIT = 27\n",
    "\n",
    "# 모델별 하이퍼파라미터 딕셔너리\n",
    "params = {\n",
    "    'lightgbm': {\n",
    "        'objective': 'mape',\n",
    "        'verbose': -1,\n",
    "        'learning_rate': 0.04920408281422388,\n",
    "        'num_leaves': 84,\n",
    "        'max_depth': 9,\n",
    "        'min_child_samples': 62,\n",
    "        'subsample': 0.8114337992568297,\n",
    "        'colsample_bytree': 0.9241942074377165,\n",
    "        'reg_alpha': 0.13177582213039427,\n",
    "        'reg_lambda': 0.8708071123519207,\n",
    "        'n_jobs': -1\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'verbosity': 0,\n",
    "        'learning_rate': 0.05794263457885568,\n",
    "        'max_depth': 6,\n",
    "        'min_child_weight': 4,\n",
    "        'subsample': 0.7344045283452703,\n",
    "        'colsample_bytree': 0.9038004924012054,\n",
    "        'reg_alpha': 0.021676042228145752,\n",
    "        'reg_lambda': 0.0010158057245436504,\n",
    "        'n_jobs': -1,\n",
    "    },\n",
    "    'randomforest': {\n",
    "        'n_estimators': 202,\n",
    "        'max_depth': 22,\n",
    "        'min_samples_split': 12,\n",
    "        'min_samples_leaf': 4,\n",
    "        'max_features': 0.5197759173571685,\n",
    "        'n_jobs': -1,  # 모든 CPU 코어 사용\n",
    "        'random_state': 42\n",
    "    },\n",
    "    'final_estimator': {\n",
    "        'objective': 'mape',\n",
    "        'verbose': -1,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "}\n",
    "\n",
    "# TimeSeriesSplit 설정\n",
    "tscv = TimeSeriesSplit(n_splits=N_SPLIT)\n",
    "\n",
    "# 스태킹 앙상블을 위한 기본 모델 설정\n",
    "base_estimators = [\n",
    "    ('lightgbm', lgb.LGBMRegressor(**params['lightgbm'])),\n",
    "    ('xgboost', xgb.XGBRegressor(**params['xgboost'])),\n",
    "    ('randomforest', RandomForestRegressor(**params['randomforest']))\n",
    "]\n",
    "\n",
    "# 최종 메타 모델로 LightGBM 설정\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=lgb.LGBMRegressor(**params['final_estimator'])\n",
    ")\n",
    "\n",
    "# MAPE 점수 리스트\n",
    "mape_scores = []\n",
    "trials = 1\n",
    "\n",
    "# TimeSeriesSplit을 이용한 검증\n",
    "for train_idx, val_idx in tscv.split(X_train):\n",
    "    if trials <= N_SPLIT - N_TEST:\n",
    "        trials += 1\n",
    "        continue\n",
    "\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    # Stacking 모델 학습\n",
    "    stacking_model.fit(X_tr, y_tr.values.ravel())\n",
    "    \n",
    "    # 예측 및 MAPE 계산\n",
    "    y_pred = stacking_model.predict(X_val)\n",
    "    mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "    mape_scores.append(mape)\n",
    "    print(f\"validation MAPE: {mape}\")\n",
    "\n",
    "# 테스트 세트에 대한 최종 예측\n",
    "stacking_model.fit(X_train, y_train.values.ravel())\n",
    "y_test_pred = stacking_model.predict(X_test)\n",
    "test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\nResults:\")\n",
    "print(\"Average Validation MAPE:\", np.mean(mape_scores))\n",
    "print(\"Validation MAPE Std Dev:\", np.std(mape_scores))\n",
    "print(\"Final Test MAPE:\", test_mape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib\n",
    "# from matplotlib import font_manager, rc\n",
    "# import numpy as np\n",
    "\n",
    "# font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/HANDotum.ttf\").get_name()\n",
    "# rc('font', family=font_name)\n",
    "# matplotlib.rcParams['axes.unicode_minus'] = False  \n",
    "# import shap\n",
    "\n",
    "# # 1. Feature Importance (LightGBM 제공)\n",
    "# # Feature importance 시각화\n",
    "# feature_importances = lgb_model.feature_importances_\n",
    "# feature_names = X_train.columns\n",
    "\n",
    "# # Feature Importance 정렬 (내림차순)\n",
    "# sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "# sorted_feature_importances = feature_importances[sorted_idx]\n",
    "# sorted_feature_names = X_train.columns[sorted_idx]\n",
    "\n",
    "# # 정렬된 중요도 막대그래프\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.barh(sorted_feature_names, sorted_feature_importances, align='center')\n",
    "# plt.xlabel(\"Feature Importance\")\n",
    "# plt.title(\"Feature Importance from LightGBM Model (Sorted)\")\n",
    "# plt.gca().invert_yaxis()  # y축을 내림차순으로 정렬\n",
    "# plt.show()\n",
    "\n",
    "# # 2. SHAP Analysis\n",
    "# # SHAP 값을 계산하고, 각 feature의 영향력을 시각화\n",
    "# explainer = shap.TreeExplainer(lgb_model)\n",
    "# shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# # Summary plot: 전체 feature의 SHAP 값 시각화\n",
    "# shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 포인트의 SHAP waterfall plot 생성\n",
    "# shap.waterfall_plot(shap.Explanation(values=shap_values[19182], base_values=explainer.expected_value, data=X_train.iloc[14022]))\n",
    "\n",
    "# # 그래프 표시\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
